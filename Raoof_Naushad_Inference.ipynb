{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc1c507-dfae-4b15-96ba-81a85fb2913d",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "278dbf9d-e991-44e6-822a-e18122f3671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import ssl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebacf9f8-719c-47c9-b017-9fb6ad9889e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261d8be-c767-445c-8086-470151f920c1",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94f6644-f8ad-41c1-97fc-d8aad402e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = './data/train.csv'\n",
    "BASE_MODEL_PATH = './models/'\n",
    "\n",
    "RANDOM_STATE = 98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdf768-7fd8-4e26-bf52-53581ff37633",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0676b91d-22dd-4501-83fd-cf56780d3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK datasets\n",
    "def download_nltk_resources():\n",
    "    try:\n",
    "        _create_unverified_https_context = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text) \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) \n",
    "    text = re.sub(r'@\\w+', '', text)  \n",
    "    text = re.sub(r'#\\w+', '', text)  \n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "# Function for lemmatizing words in the text\n",
    "def lemmatize_words(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in word_tokens])\n",
    "    return lemmatized_text\n",
    "\n",
    "# Main preprocessing function\n",
    "def preprocess_data(df, text_column_name='text', target_column_name='sentiment', columns_to_remove=[]):\n",
    "    df[text_column_name] = df[text_column_name].astype(str)\n",
    "    df[text_column_name] = df[text_column_name].apply(clean_text)\n",
    "    df[text_column_name] = df[text_column_name].apply(remove_stopwords)\n",
    "    df[text_column_name] = df[text_column_name].apply(lemmatize_words)\n",
    "    df[target_column_name] = df[target_column_name].map({\"negative\": 0, \"neutral\": 1, \"positive\": 2})\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0799a3-1a54-4d57-bb77-82c6931f2816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Load a saved model from a specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_path: str, path to the saved model (.pkl file)\n",
    "    \n",
    "    Returns:\n",
    "    - Loaded model\n",
    "    \"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set and print the classification report and accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The machine learning model to evaluate\n",
    "    - X_test: Features of the test set\n",
    "    - y_test: True labels of the test set\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b021e6-93fe-44b6-a2e5-b198a62a1978",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d2efd2-a26e-4a3d-ac8c-968ed507ed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/raoofmac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/raoofmac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/raoofmac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/raoofmac/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "download_nltk_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b8716c-afd2-41eb-9096-bc76a8add30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(DATA_FILE_PATH, encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c9193bc-fafc-4867-8f95-c19066b4d976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>responded going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bos bullying</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son put release already bought</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  sentiment\n",
       "0                 responded going          1\n",
       "1         sooo sad miss san diego          0\n",
       "2                    bos bullying          0\n",
       "3           interview leave alone          0\n",
       "4  son put release already bought          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove = ['textID', 'Time of Tweet', 'selected_text', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\n",
    "\n",
    "# Preprocess data\n",
    "df_processed = preprocess_data(df, text_column_name='text', columns_to_remove=columns_to_remove)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef517a0-c0ab-4c92-9df3-cb044f6370fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_processed['text'], df_processed['sentiment'], test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1adf966-2b39-443c-b8cf-c3bacdbca795",
   "metadata": {},
   "source": [
    "## Inference with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78831514-71ec-4f88-96a1-af86eceeee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: Logistic Regression\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66      1525\n",
      "           1       0.65      0.76      0.70      2225\n",
      "           2       0.79      0.74      0.76      1747\n",
      "\n",
      "    accuracy                           0.71      5497\n",
      "   macro avg       0.72      0.70      0.71      5497\n",
      "weighted avg       0.72      0.71      0.71      5497\n",
      "\n",
      "Accuracy: 0.7111\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr_path = os.path.join(BASE_MODEL_PATH, 'lr_model.pkl')\n",
    "print(f\"Evaluating model: Logistic Regression\")\n",
    "model = load_model(lr_path)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "print(\"-\" * 80) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40081c5a-3a3e-4a5c-93e1-48799524c05d",
   "metadata": {},
   "source": [
    "## Inference with Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5765afd-87b6-42f6-8f0f-31b3274f544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: Multinomical Naive Bayes\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.49      0.59      1525\n",
      "           1       0.57      0.79      0.66      2225\n",
      "           2       0.76      0.60      0.67      1747\n",
      "\n",
      "    accuracy                           0.65      5497\n",
      "   macro avg       0.69      0.63      0.64      5497\n",
      "weighted avg       0.67      0.65      0.64      5497\n",
      "\n",
      "Accuracy: 0.6460\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr_path = os.path.join(BASE_MODEL_PATH, 'multinomialNB_model.pkl')\n",
    "print(f\"Evaluating model: Multinomical Naive Bayes\")\n",
    "model = load_model(lr_path)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "print(\"-\" * 80) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6795c-1706-430d-87d1-3d0c104c4629",
   "metadata": {},
   "source": [
    "## Inference with RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e1e0ef0-b160-4799-afb1-810542fb3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: Random Forest Model\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.53      0.62      1525\n",
      "           1       0.64      0.79      0.70      2225\n",
      "           2       0.76      0.73      0.74      1747\n",
      "\n",
      "    accuracy                           0.70      5497\n",
      "   macro avg       0.72      0.68      0.69      5497\n",
      "weighted avg       0.71      0.70      0.69      5497\n",
      "\n",
      "Accuracy: 0.6967\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr_path = os.path.join(BASE_MODEL_PATH, 'random_forestmodel.pkl')\n",
    "print(f\"Evaluating model: Random Forest Model\")\n",
    "model = load_model(lr_path)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "print(\"-\" * 80) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RN Venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
